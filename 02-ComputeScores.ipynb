{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "from glob import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_ner(true_entities, predicted_entities):\n",
    "\ttp, fp, fn = 0, 0, 0\n",
    "\n",
    "\ttrue_set = {(ent['pos'][0], ent['pos'][1], ent['type']) for ent in true_entities}\n",
    "\tpred_set = {(ent['start'], ent['end'], ent['label']) for ent in predicted_entities}\n",
    "\n",
    "\ttp = len(true_set & pred_set)  # Intersection: Correctly predicted\n",
    "\tfp = len(pred_set - true_set)  # Predicted but not in ground truth\n",
    "\tfn = len(true_set - pred_set)  # Ground truth but not predicted\n",
    "\n",
    "\tprecision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "\trecall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "\tf1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "\treturn {\"Precision\": precision, \"Recall\": recall, \"F1-score\": f1_score}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_files = glob(\"data/NEREvalsLast/*.json\")\n",
    "\n",
    "all_scores = {}\n",
    "\n",
    "for pred_file in pred_files:\n",
    "\tname = os.path.basename(pred_file).replace(\".json\", \"\")\n",
    "\texp_file = f\"data/IE_INSTRUCTIONS/NER/{name}/test.json\"\n",
    "\t\n",
    "\tpredictions = json.load(open(pred_file))\n",
    "\texpected = json.load(open(exp_file))\n",
    "\n",
    "\tthrs = [\n",
    "\t\ti / 10 for i in range(1, 10)\n",
    "\t]\n",
    "\tscores = {\n",
    "\t\ti: [\n",
    "\t\t\tevaluate_ner(k1[\"entities\"], [n for n in k2 if n[\"score\"] > i]) for k1, k2 in zip(expected, predictions)\n",
    "\t\t] for i in thrs\n",
    "\t}\n",
    "\n",
    "\tfinal_scores = pd.DataFrame({\n",
    "\t\tk: pd.DataFrame(score).mean() for k, score in scores.items()\n",
    "\t})\n",
    "\tall_scores[name] = final_scores.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.1: {'Precision': 0.2936410196262413,\n",
       "  'Recall': 0.1866251769576893,\n",
       "  'F1-score': 0.2171485046446325},\n",
       " 0.2: {'Precision': 0.26718664477285164,\n",
       "  'Recall': 0.1447400608422776,\n",
       "  'F1-score': 0.17696128057216726},\n",
       " 0.3: {'Precision': 0.25467100633356793,\n",
       "  'Recall': 0.12121984815950333,\n",
       "  'F1-score': 0.1536939761062441},\n",
       " 0.4: {'Precision': 0.2456486042692939,\n",
       "  'Recall': 0.10166593464007258,\n",
       "  'F1-score': 0.13467792454173214},\n",
       " 0.5: {'Precision': 0.21747302369223548,\n",
       "  'Recall': 0.08364616021635726,\n",
       "  'F1-score': 0.11201425450012814},\n",
       " 0.6: {'Precision': 0.20155993431855504,\n",
       "  'Recall': 0.07153817378571073,\n",
       "  'F1-score': 0.09787139048546879},\n",
       " 0.7: {'Precision': 0.14244663382594416,\n",
       "  'Recall': 0.04388048322777387,\n",
       "  'F1-score': 0.06233502961043796},\n",
       " 0.8: {'Precision': 0.05295566502463054,\n",
       "  'Recall': 0.01683477988896708,\n",
       "  'F1-score': 0.023827944086564773},\n",
       " 0.9: {'Precision': 0.0, 'Recall': 0.0, 'F1-score': 0.0}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores[\"ACE 2004\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/Results/alexmodel-last.json\", \"w\") as f:\n",
    "    json.dump(all_scores, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
