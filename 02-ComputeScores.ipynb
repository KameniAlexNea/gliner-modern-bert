{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_ner(true_entities, predicted_entities):\n",
    "\ttp, fp, fn = 0, 0, 0\n",
    "\n",
    "\ttrue_set = {(ent['pos'][0], ent['pos'][1], ent['type']) for ent in true_entities}\n",
    "\tpred_set = {(ent['start'], ent['end'], ent['label']) for ent in predicted_entities}\n",
    "\n",
    "\ttp = len(true_set & pred_set)  # Intersection: Correctly predicted\n",
    "\tfp = len(pred_set - true_set)  # Predicted but not in ground truth\n",
    "\tfn = len(true_set - pred_set)  # Ground truth but not predicted\n",
    "\n",
    "\tprecision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "\trecall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "\tf1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "\treturn {\"Precision\": precision, \"Recall\": recall, \"F1-score\": f1_score}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4797, 4797)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_file = \"data/NEREvals/bc5cdr.json\"\n",
    "exp_file = \"data/IE_INSTRUCTIONS/NER/bc5cdr/test.json\"\n",
    "\n",
    "predictions = json.load(open(pred_file))\n",
    "expected = json.load(open(exp_file))\n",
    "\n",
    "len(predictions), len(expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'start': 19,\n",
       "  'end': 42,\n",
       "  'text': 'ventricular tachycardia',\n",
       "  'label': 'Disease',\n",
       "  'score': 0.36110201478004456},\n",
       " {'start': 72,\n",
       "  'end': 82,\n",
       "  'text': 'dobutamine',\n",
       "  'label': 'Chemical',\n",
       "  'score': 0.8203075528144836},\n",
       " {'start': 111,\n",
       "  'end': 133,\n",
       "  'text': 'dilated cardiomyopathy',\n",
       "  'label': 'Disease',\n",
       "  'score': 0.9815657138824463},\n",
       " {'start': 138,\n",
       "  'end': 162,\n",
       "  'text': 'congestive heart failure',\n",
       "  'label': 'Disease',\n",
       "  'score': 0.9569717645645142}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Torsade de pointes', 'type': 'Disease', 'pos': [0, 18]},\n",
       " {'name': 'ventricular tachycardia', 'type': 'Disease', 'pos': [19, 42]},\n",
       " {'name': 'dobutamine', 'type': 'Chemical', 'pos': [72, 82]},\n",
       " {'name': 'dilated cardiomyopathy', 'type': 'Disease', 'pos': [111, 133]},\n",
       " {'name': 'congestive heart failure', 'type': 'Disease', 'pos': [138, 162]}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected[0][\"entities\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "thrs = [\n",
    "\ti / 10 for i in range(1, 10)\n",
    "]\n",
    "scores = {\n",
    "\ti: [\n",
    "\t\tevaluate_ner(k1[\"entities\"], [n for n in k2 if n[\"score\"] > i]) for k1, k2 in zip(expected, predictions)\n",
    "\t] for i in thrs\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.1: Precision    0.532425\n",
       " Recall       0.594687\n",
       " F1-score     0.546447\n",
       " dtype: float64,\n",
       " 0.2: Precision    0.552919\n",
       " Recall       0.581224\n",
       " F1-score     0.551955\n",
       " dtype: float64,\n",
       " 0.3: Precision    0.563158\n",
       " Recall       0.567636\n",
       " F1-score     0.550225\n",
       " dtype: float64,\n",
       " 0.4: Precision    0.568285\n",
       " Recall       0.553066\n",
       " F1-score     0.544819\n",
       " dtype: float64,\n",
       " 0.5: Precision    0.570473\n",
       " Recall       0.531965\n",
       " F1-score     0.534046\n",
       " dtype: float64,\n",
       " 0.6: Precision    0.570928\n",
       " Recall       0.506465\n",
       " F1-score     0.519089\n",
       " dtype: float64,\n",
       " 0.7: Precision    0.561612\n",
       " Recall       0.466462\n",
       " F1-score     0.490973\n",
       " dtype: float64,\n",
       " 0.8: Precision    0.534985\n",
       " Recall       0.404136\n",
       " F1-score     0.440472\n",
       " dtype: float64,\n",
       " 0.9: Precision    0.419705\n",
       " Recall       0.272395\n",
       " F1-score     0.313661\n",
       " dtype: float64}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "\tk: pd.DataFrame(score).mean() for k, score in scores.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.7</th>\n",
       "      <th>0.8</th>\n",
       "      <th>0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.532425</td>\n",
       "      <td>0.552919</td>\n",
       "      <td>0.563158</td>\n",
       "      <td>0.568285</td>\n",
       "      <td>0.570473</td>\n",
       "      <td>0.570928</td>\n",
       "      <td>0.561612</td>\n",
       "      <td>0.534985</td>\n",
       "      <td>0.419705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.594687</td>\n",
       "      <td>0.581224</td>\n",
       "      <td>0.567636</td>\n",
       "      <td>0.553066</td>\n",
       "      <td>0.531965</td>\n",
       "      <td>0.506465</td>\n",
       "      <td>0.466462</td>\n",
       "      <td>0.404136</td>\n",
       "      <td>0.272395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-score</th>\n",
       "      <td>0.546447</td>\n",
       "      <td>0.551955</td>\n",
       "      <td>0.550225</td>\n",
       "      <td>0.544819</td>\n",
       "      <td>0.534046</td>\n",
       "      <td>0.519089</td>\n",
       "      <td>0.490973</td>\n",
       "      <td>0.440472</td>\n",
       "      <td>0.313661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0.1       0.2       0.3       0.4       0.5       0.6  \\\n",
       "Precision  0.532425  0.552919  0.563158  0.568285  0.570473  0.570928   \n",
       "Recall     0.594687  0.581224  0.567636  0.553066  0.531965  0.506465   \n",
       "F1-score   0.546447  0.551955  0.550225  0.544819  0.534046  0.519089   \n",
       "\n",
       "                0.7       0.8       0.9  \n",
       "Precision  0.561612  0.534985  0.419705  \n",
       "Recall     0.466462  0.404136  0.272395  \n",
       "F1-score   0.490973  0.440472  0.313661  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_scores = pd.DataFrame({\n",
    "\tk: pd.DataFrame(score).mean() for k, score in scores.items()\n",
    "})\n",
    "final_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "pred_files = glob(\"data/NEREvals/*.json\")\n",
    "\n",
    "all_scores = {}\n",
    "\n",
    "for pred_file in pred_files:\n",
    "\tname = os.path.basename(pred_file).replace(\".json\", \"\")\n",
    "\texp_file = f\"data/IE_INSTRUCTIONS/NER/{name}/test.json\"\n",
    "\t\n",
    "\tpredictions = json.load(open(pred_file))\n",
    "\texpected = json.load(open(exp_file))\n",
    "\n",
    "\tthrs = [\n",
    "\t\ti / 10 for i in range(1, 10)\n",
    "\t]\n",
    "\tscores = {\n",
    "\t\ti: [\n",
    "\t\t\tevaluate_ner(k1[\"entities\"], [n for n in k2 if n[\"score\"] > i]) for k1, k2 in zip(expected, predictions)\n",
    "\t\t] for i in thrs\n",
    "\t}\n",
    "\n",
    "\tfinal_scores = pd.DataFrame({\n",
    "\t\tk: pd.DataFrame(score).mean() for k, score in scores.items()\n",
    "\t})\n",
    "\tall_scores[name] = final_scores.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.1: {'Precision': 0.3112232014017728,\n",
       "  'Recall': 0.28590096616574445,\n",
       "  'F1-score': 0.2840903811115719},\n",
       " 0.2: {'Precision': 0.33739319656807343,\n",
       "  'Recall': 0.27812621833557793,\n",
       "  'F1-score': 0.291823340869098},\n",
       " 0.3: {'Precision': 0.35093781765579796,\n",
       "  'Recall': 0.2651394719128709,\n",
       "  'F1-score': 0.2894997544368719},\n",
       " 0.4: {'Precision': 0.3559235475799515,\n",
       "  'Recall': 0.24991496256890344,\n",
       "  'F1-score': 0.2808608478123607},\n",
       " 0.5: {'Precision': 0.3558707678473689,\n",
       "  'Recall': 0.23425607301838827,\n",
       "  'F1-score': 0.26844120811592104},\n",
       " 0.6: {'Precision': 0.3534385018375166,\n",
       "  'Recall': 0.21794224863806144,\n",
       "  'F1-score': 0.25515812593581483},\n",
       " 0.7: {'Precision': 0.3509974392055673,\n",
       "  'Recall': 0.20032163717508544,\n",
       "  'F1-score': 0.23984668679541307},\n",
       " 0.8: {'Precision': 0.33739492923606224,\n",
       "  'Recall': 0.17140167577359694,\n",
       "  'F1-score': 0.21263185367142315},\n",
       " 0.9: {'Precision': 0.2996100164203612,\n",
       "  'Recall': 0.12692366131405539,\n",
       "  'F1-score': 0.1644231897002833}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores[\"ACE 2004\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/Results/gliner-med.json\", \"w\") as f:\n",
    "    json.dump(all_scores, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
